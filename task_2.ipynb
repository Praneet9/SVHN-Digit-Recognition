{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Street View House Numbers Classification\n",
    "\n",
    "\n",
    "\n",
    "The data of the Street View House Numbers dataset, which can originally be found here are originally in .mat, i.e. files which can be best processed with MATLAB; thus, some preprocessing is required (see section 2). It is important to note that the data are divided into two formats and in this particular kernel we are going to use Format 2:\n",
    "\n",
    "* Format 1: The original, variable-resolution colored house-number images with character level bounding boxes.\n",
    "* Format 2: The cropped digits (32x32 pixels) which follow the philosophy of the MNIST dataset more closely, but also contain some distracting digits to the sides of the digit of interest.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torch.utils import data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Dataset Class\n",
    "\n",
    "To load and preprocess data  \n",
    "Referred to [kaggle](https://www.kaggle.com/dimitriosroussis/svhn-classification-with-cnn-keras-96-acc) for reading mat type data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHN(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset_dir, data_path):\n",
    "        # Using scipy's loadmat to read files of type 'mat'\n",
    "        raw_data = loadmat(os.path.join(dataset_dir, data_path))\n",
    "        \n",
    "        images = np.array(raw_data['X'])\n",
    "        # Changing axes to represent data in B, C, H, W format\n",
    "        self.data = images.transpose((3, 2, 0, 1))\n",
    "        \n",
    "        self.labels = raw_data['y']\n",
    "        # Changing labels of 0 that are set as 10 originally\n",
    "        # in the dataset back to 0\n",
    "        self.labels[self.labels == 10] = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Normalizing data\n",
    "        img = self.data[idx] / 255.\n",
    "        target = np.array(self.labels[idx]).astype(np.float)\n",
    "        \n",
    "        return {\n",
    "            'image': torch.from_numpy(img).type(torch.FloatTensor),\n",
    "            'target': torch.from_numpy(target).type(torch.LongTensor).squeeze()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Model Architecture\n",
    "\n",
    "Used 4 blocks of (3 Conv layers, 1 Batch Normalization and 1 Dropout layer each)  \n",
    "Each block has a residual connection with the previous block  \n",
    "4 Blocks are followed by a global pooling layer and 2 linear layers, the last linear layer being the output layer  \n",
    "Haven't used pooling layers as the data dimension is too low and may result in information loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Block 1\n",
    "        self.conv_1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv_2 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv_3 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.batch_1 = nn.BatchNorm2d(32)\n",
    "        self.dropout_1 = nn.Dropout()\n",
    "        \n",
    "        # Residual Connection 1\n",
    "        self.res_1 = nn.Conv2d(32, 64, 5, 1)\n",
    "        \n",
    "        # Block 2\n",
    "        self.conv_4 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.conv_5 = nn.Conv2d(64, 64, 3, 1)\n",
    "        self.conv_6 = nn.Conv2d(64, 64, 3, 1)\n",
    "        self.batch_2 = nn.BatchNorm2d(64)\n",
    "        self.dropout_2 = nn.Dropout()\n",
    "        \n",
    "        # Residual Connection 2\n",
    "        self.res_2 = nn.Conv2d(64, 128, 7, 1)\n",
    "        \n",
    "        # Block 3\n",
    "        self.conv_7 = nn.Conv2d(64, 128, 3, 1)\n",
    "        self.conv_8 = nn.Conv2d(128, 128, 3, 1)\n",
    "        self.conv_9 = nn.Conv2d(128, 128, 3, 1)\n",
    "        self.batch_3 = nn.BatchNorm2d(128)\n",
    "        self.dropout_3 = nn.Dropout()\n",
    "        \n",
    "        # Residual Connection 3\n",
    "        self.res_3 = nn.Conv2d(128, 256, 7, 1)\n",
    "        \n",
    "        # Block 4\n",
    "        self.conv_10 = nn.Conv2d(128, 256, 3, 1)\n",
    "        self.conv_11 = nn.Conv2d(256, 256, 3, 1)\n",
    "        self.conv_12 = nn.Conv2d(256, 256, 3, 1)\n",
    "        self.batch_4 = nn.BatchNorm2d(256)\n",
    "        self.dropout_4 = nn.Dropout()\n",
    "        \n",
    "        # Residual Connection 4\n",
    "        self.res_4 = nn.Conv2d(256, 256, 5, 1)\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.linear_1 = nn.Linear(256, 64)\n",
    "        self.output = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # First Block\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        \n",
    "        # First residual branch\n",
    "        res_1 = F.relu(self.res_1(x))\n",
    "        \n",
    "        x = F.relu(self.conv_3(x))\n",
    "        x = self.batch_1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        \n",
    "        # Second block\n",
    "        x = F.relu(self.conv_4(x))\n",
    "        \n",
    "        # Adding residual connection from first block\n",
    "        add_1 = torch.add(x, res_1)\n",
    "        # Second residual branch\n",
    "        res_2 = F.relu(self.res_2(add_1))\n",
    "        \n",
    "        x = F.relu(self.conv_5(add_1))\n",
    "        x = F.relu(self.conv_6(x))\n",
    "        x = self.batch_2(x)\n",
    "        x = self.dropout_2(x)\n",
    "        \n",
    "        # Third block\n",
    "        x = F.relu(self.conv_7(x))\n",
    "        \n",
    "        # Adding residual connection from second block\n",
    "        add_2 = torch.add(x, res_2)\n",
    "        # Third residual branch\n",
    "        res_3 = F.relu(self.res_3(add_2))\n",
    "        \n",
    "        x = F.relu(self.conv_8(x))\n",
    "        x = F.relu(self.conv_9(x))\n",
    "        x = self.batch_3(x)\n",
    "        x = self.dropout_3(x)\n",
    "        \n",
    "        # Fourth block\n",
    "        x = F.relu(self.conv_10(x))\n",
    "        \n",
    "        # Adding residual connection from third block\n",
    "        add_3 = torch.add(x, res_3)\n",
    "        # Fourth residual branch\n",
    "        res_4 = F.relu(self.res_4(add_3))\n",
    "        \n",
    "        x = F.relu(self.conv_11(x))\n",
    "        x = F.relu(self.conv_12(x))\n",
    "        x = self.batch_4(x)\n",
    "        x = self.dropout_4(x)\n",
    "        \n",
    "        # Adding residual connection from fourth block\n",
    "        add_4 = torch.add(x, res_4)\n",
    "        # Global Average Pooling\n",
    "        x = self.gap(add_4)\n",
    "        \n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        \n",
    "        x = F.relu(self.linear_1(x))\n",
    "        \n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Config Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = '/home/praneet/Downloads'\n",
    "TRAIN_PATH = 'train_32x32.mat'\n",
    "TEST_PATH = 'test_32x32.mat'\n",
    "WIDTH = 32\n",
    "HEIGHT = 32\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) SVHN Classifier\n",
    "\n",
    "This class handles all the parts of the whole pipeline  \n",
    "It includes, data loading and preparing, initializing the model and other hyperparameters  \n",
    "It also includes training, evaluating, inferencing, loading and saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHNClassifier():\n",
    "    \n",
    "    def __init__(self, model, mode='eval', model_path=None, LEARNING_RATE=0.0001, BATCH_SIZE=16):\n",
    "        \n",
    "        # Initializing config parameters\n",
    "        self.HEIGHT = HEIGHT\n",
    "        self.WIDTH= WIDTH\n",
    "        self.CHANNELS = 3\n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "        self.VAL_SPLIT = 0.1\n",
    "        self.EPOCHS = EPOCHS\n",
    "        self.LEARNING_RATE = LEARNING_RATE\n",
    "        self.mode = mode\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Loading the model in different modes\n",
    "        if mode in ['train', 'test']:\n",
    "            \n",
    "            self.model = model.to(self.device)\n",
    "            \n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters(), \n",
    "                                              lr=self.LEARNING_RATE)\n",
    "            \n",
    "            # If the class is initialized in testing mode, training data is not loaded\n",
    "            if mode == \"test\":\n",
    "                assert model_path is not None, \"Please provide model path to test\"\n",
    "                self.load_model(model_path)\n",
    "            else:\n",
    "                \n",
    "                # Loading and splitting the dataset into train and val sets\n",
    "                train_dataset = SVHN(DATASET_DIR, TRAIN_PATH)\n",
    "\n",
    "                VAL_DATA_LEN = int(len(train_dataset) * self.VAL_SPLIT)\n",
    "                TRAIN_DATA_LEN = len(train_dataset) - VAL_DATA_LEN\n",
    "\n",
    "                self.train_set, self.val_set = data.random_split(train_dataset, \n",
    "                                                                 [TRAIN_DATA_LEN, \n",
    "                                                                  VAL_DATA_LEN])\n",
    "            # Loading the test set\n",
    "            self.test_set = SVHN(DATASET_DIR, TEST_PATH)\n",
    "            \n",
    "            # Loss and accuracy history lists\n",
    "            self.train_loss_history = []\n",
    "            self.val_loss_history = []\n",
    "            \n",
    "            self.train_acc_history = []\n",
    "            self.val_acc_history = []\n",
    "            \n",
    "        else:\n",
    "            # Loading in inference mode where datasets are not required\n",
    "            assert model_path is not None, \"Please provide model path to use\"\n",
    "            self.model = model.to(self.device)\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters(), \n",
    "                                              lr=self.LEARNING_RATE)\n",
    "            if model_path.endswith('pth'):\n",
    "                self.load_model(model_path)\n",
    "            elif model_path.endswith('pt'):\n",
    "                self.load_state_dict(model_path)\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "            Trains the model on given epochs in the config parameter\n",
    "        \"\"\"\n",
    "        \n",
    "        # Tensorboard summary writer for maintaining logs\n",
    "        writer = SummaryWriter(comment=f\"{type(self.model).__name__}_LR_{LEARNING_RATE}_EPOCHS_{self.EPOCHS}_VAL_LOSS\")\n",
    "        \n",
    "        # Early stopping for stopping the training after the val loss starts increasing or diverging\n",
    "        early_stopping = EarlyStopping(patience=10, verbose=True, path='val_loss.pt')\n",
    "    \n",
    "        # Training loop\n",
    "        for epoch in range(1, self.EPOCHS + 1):\n",
    "\n",
    "            train_loss = 0.0\n",
    "            train_acc = 0.0\n",
    "            train_loss_history = []\n",
    "            train_acc_history = []\n",
    "            \n",
    "            self.model.train()\n",
    "            for idx, sample in enumerate(self.training_data):\n",
    "                \n",
    "                # Iterating over data and moving it to GPU\n",
    "                image = sample['image'].to(self.device)\n",
    "                target = sample['target'].to(self.device)\n",
    "                \n",
    "                # Forward Pass\n",
    "                outputs = F.softmax(self.model(image), dim=1)\n",
    "                \n",
    "                # Calculating the class predictions\n",
    "                _, correct_predictions = torch.max(outputs, 1)          \n",
    "                \n",
    "                # Calculating loss\n",
    "                loss = self.criterion(outputs, target)\n",
    "                \n",
    "                # Backpropagation\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # Maintaining training logs\n",
    "                train_acc_history.append(torch.sum(correct_predictions == target).item() / self.BATCH_SIZE)\n",
    "                train_loss_history.append(loss.item() / self.BATCH_SIZE)\n",
    "                \n",
    "                # Printing metrics in place\n",
    "                print(f\"Epoch {epoch}: Batch ({idx+1}/{len(self.training_data)}) \\\n",
    "                      Training Accuracy: {round(sum(train_acc_history) / (idx+1), 5)} \\\n",
    "                      Training Loss: {round(sum(train_loss_history) / (idx+1), 5)}\", end=\"\\r\")\n",
    "\n",
    "            else:\n",
    "                # Evaluating model on validation set\n",
    "                val_acc, val_loss = self.evaluate(self.validation_data)\n",
    "                \n",
    "                # Calculating metrics\n",
    "                train_acc = sum(train_acc_history) / (idx+1)\n",
    "                train_loss = sum(train_loss_history) / (idx+1)\n",
    "                \n",
    "                self.train_acc_history.append(train_acc)\n",
    "                self.val_acc_history.append(val_acc)\n",
    "                \n",
    "                self.train_loss_history.append(train_loss)\n",
    "                self.val_loss_history.append(val_loss)\n",
    "                \n",
    "                # Writing training logs to tensorboard\n",
    "                writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "                writer.add_scalar('Accuracy/validation', val_acc, epoch)\n",
    "                \n",
    "                # Writing evaluation logs to tensorboard\n",
    "                writer.add_scalar('Loss/train', train_loss / (idx+1), epoch)\n",
    "                writer.add_scalar('Loss/validation', val_loss, epoch)\n",
    "                \n",
    "                print(f\"Epoch {epoch}: \\\n",
    "                      Training Accuracy: {round(train_acc, 5)} \\\n",
    "                      Training Loss: {round(train_loss, 5)} \\\n",
    "                      Validation Accuracy: {round(val_acc, 5)} \\\n",
    "                      Validation Loss: {round(val_loss, 5)}\")\n",
    "                \n",
    "            early_stopping(val_loss, self.model)\n",
    "            \n",
    "            # If early stopping is triggered, training loop will stop\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "        # Closing tensorboard connection\n",
    "        writer.flush()\n",
    "        writer.close()\n",
    "        \n",
    "        # Saving best and latest model\n",
    "        model_name = f\"LR_{self.LEARNING_RATE}_EPOCHS_{self.EPOCHS}.pth\"\n",
    "        best_model_name = f\"BEST_LR_{self.LEARNING_RATE}_EPOCHS_{self.EPOCHS}.pth\"\n",
    "        self.save_model(model_name)\n",
    "        self.load_state_dict('val_loss.pt')\n",
    "        self.save_model(best_model_name)\n",
    "    \n",
    "    def evaluate(self, test_data=None):\n",
    "        \"\"\"\n",
    "        Evaluates the model on the given test data\n",
    "        Args:\n",
    "            test_data: Custom test data for evaluation\n",
    "        Returns:\n",
    "            test_acc: Test Set accuracy\n",
    "            test_loss: Test Set loss\n",
    "        \"\"\"\n",
    "        \n",
    "        # If custom test data is not given, use the initialized test data\n",
    "        if test_data is None:\n",
    "            test_data = self.test_data\n",
    "        \n",
    "        # Setting the model in evaluation mode\n",
    "        self.model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_acc = 0.0\n",
    "        \n",
    "        # Evaluating the model without calculating gradients\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for sample in test_data:\n",
    "                image = sample['image'].to(self.device)\n",
    "                target = sample['target'].to(self.device)\n",
    "\n",
    "                outputs = F.softmax(self.model(image), dim=1)\n",
    "                \n",
    "                correct_predictions = torch.max(outputs, 1)[-1]\n",
    "                test_acc += torch.sum(correct_predictions == target).item() / self.BATCH_SIZE\n",
    "                                                  \n",
    "                pred_loss = self.criterion(outputs, target)    \n",
    "                test_loss += pred_loss.item() / self.BATCH_SIZE\n",
    "                \n",
    "            test_loss = test_loss / len(test_data)\n",
    "            test_acc = test_acc / len(test_data)\n",
    "        \n",
    "        return test_acc, test_loss\n",
    "    \n",
    "    def prepare_dataset(self):\n",
    "        \"\"\"\n",
    "        Prepares dataset with dataloaders and given transforms, setting different parameters\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "        \n",
    "            self.training_data = data.DataLoader(self.train_set,\n",
    "                                                 batch_size=self.BATCH_SIZE,\n",
    "                                                 shuffle=True,\n",
    "                                                 num_workers=2)\n",
    "            self.validation_data = data.DataLoader(self.val_set,\n",
    "                                                   batch_size=self.BATCH_SIZE,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=2)\n",
    "        self.test_data = data.DataLoader(self.test_set,\n",
    "                                         batch_size=self.BATCH_SIZE,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=2)\n",
    "    \n",
    "    def inference(self, image):\n",
    "        \"\"\"\n",
    "        Inferences given examples in eval mode\n",
    "        \n",
    "        \"\"\"\n",
    "        image = image.to(self.device)\n",
    "        \n",
    "        if len(image.shape) < 4:\n",
    "            image = torch.unsqueeze(image, 0)\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            return F.softmax(self.model(image), dim=1)\n",
    "    \n",
    "    def save_model(self, file_path='torch_model.pth'):\n",
    "        \"\"\"\n",
    "        Saves model with the given name and saves other metrics and log history with it.\n",
    "        \"\"\"\n",
    "        torch.save({\n",
    "            'epochs': self.EPOCHS,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'train_loss_history': self.train_loss_history,\n",
    "            'val_loss_history': self.val_loss_history\n",
    "            }, file_path)\n",
    "        \n",
    "        print(f\"Model saved to {file_path}\")\n",
    "    \n",
    "    def load_model(self, file_path='torch_model.pth'):\n",
    "        \"\"\"\n",
    "        Loads model with the given name and loads other metrics and log history with it\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(file_path)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.EPOCHS = checkpoint['epochs']\n",
    "        self.train_loss_history = checkpoint['train_loss_history']\n",
    "        self.val_loss_history = checkpoint['val_loss_history']\n",
    "        \n",
    "        print(f\"Model loaded from {file_path}\")\n",
    "    \n",
    "    def load_state_dict(self, file_path='loss.pt'):\n",
    "        \"\"\"\n",
    "        Loads the model weights only saved by early stopping\n",
    "        \"\"\"\n",
    "        \n",
    "        self.model.load_state_dict(torch.load(file_path))\n",
    "        \n",
    "        print(f\"Model state dict loaded from {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Initializing classifier and preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVHNClassifier(Model(), 'train')\n",
    "classifier.prepare_dataset()\n",
    "summary(classifier.model, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Loading classifier in test mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from BEST_LR_0.0001_EPOCHS_100.pth\n"
     ]
    }
   ],
   "source": [
    "classifier = SVHNClassifier(Model(), 'test', 'BEST_LR_0.0001_EPOCHS_100.pth')\n",
    "classifier.prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9320451751690227\n",
      "Test Loss: 0.09555236087595677\n"
     ]
    }
   ],
   "source": [
    "test_acc, test_loss = classifier.evaluate()\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"Test Loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Visualizing predictions and activations using GradCAM\n",
    "\n",
    "Used library from [here](https://github.com/jacobgil/pytorch-grad-cam) implemented by **jacobgil**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(classifier.test_data))\n",
    "input_tensor = sample['image'][0].unsqueeze(0)\n",
    "rgb_image = input_tensor.squeeze().numpy().transpose((1, 2, 0))\n",
    "with torch.no_grad():\n",
    "    output = classifier.model(input_tensor.to(classifier.device))\n",
    "predicted_output = torch.max(output, 1)[-1][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(rgb_image)\n",
    "plt.title(\"Original Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting gap layer as the visualization layer\n",
    "target_layer = classifier.model.conv_10\n",
    "cam = GradCAMPlusPlus(model=classifier.model, target_layer=target_layer, use_cuda=True)\n",
    "grayscale_cam = cam(input_tensor=input_tensor.to(classifier.device))\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "visualization = show_cam_on_image(rgb_image, grayscale_cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(visualization)\n",
    "plt.title(\"Predicted: \" + str(predicted_output) + \" Target: \" + str(sample['target'][0].item()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
